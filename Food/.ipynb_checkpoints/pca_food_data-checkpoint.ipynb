{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\mekho\\documents\\pycharmprojects\\venvs\\linkedin_quiz_env\\lib\\site-packages\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in c:\\users\\mekho\\documents\\pycharmprojects\\venvs\\linkedin_quiz_env\\lib\\site-packages (from seaborn)\n",
      "Requirement already satisfied: scipy>=0.14.0 in c:\\users\\mekho\\documents\\pycharmprojects\\venvs\\linkedin_quiz_env\\lib\\site-packages (from seaborn)\n",
      "Requirement already satisfied: numpy>=1.9.3 in c:\\users\\mekho\\documents\\pycharmprojects\\venvs\\linkedin_quiz_env\\lib\\site-packages (from seaborn)\n",
      "Requirement already satisfied: pandas>=0.15.2 in c:\\users\\mekho\\documents\\pycharmprojects\\venvs\\linkedin_quiz_env\\lib\\site-packages (from seaborn)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\mekho\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from matplotlib>=1.4.3->seaborn)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mekho\\documents\\pycharmprojects\\venvs\\linkedin_quiz_env\\lib\\site-packages (from matplotlib>=1.4.3->seaborn)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mekho\\documents\\pycharmprojects\\venvs\\linkedin_quiz_env\\lib\\site-packages (from matplotlib>=1.4.3->seaborn)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\mekho\\documents\\pycharmprojects\\venvs\\linkedin_quiz_env\\lib\\site-packages (from matplotlib>=1.4.3->seaborn)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\mekho\\documents\\pycharmprojects\\venvs\\linkedin_quiz_env\\lib\\site-packages (from pandas>=0.15.2->seaborn)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mekho\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from python-dateutil>=2.1->matplotlib>=1.4.3->seaborn)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mekho\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users\\mekho\\Documents\\PycharmProjects\\Quiz_Food_LinkedIn\\data\\Food\\wrangled_food_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(df.MMSANAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['city'] = df.MMSANAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.city != 'nan', :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = [str(n).split(',')[:-1].strip() for n in df.MMSANAME]\n",
    "\n",
    "# df['city'] = names\n",
    "\n",
    "# df = df.loc[df.city != 'nan', :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_selected_features = ['city', 'FTJUDA2_', 'FRUTDA2_', 'GRENDA1_', 'FRNCHDA_', 'POTADA1_',\n",
    "                          'VEGEDA2_', '_FRUTSU1', '_VEGESU1', '_FRTLT1A', '_VEGLT1A', \n",
    "                          '_FRT16A', '_VEG23A'] #'FRUITE1', '_VEGETE1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, list_selected_features].reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_select = [c for c in df.columns if c.startswith('_')]\n",
    "# columns_to_select = ['city'] + columns_to_select\n",
    "# df = df.loc[:, columns_to_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('city', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_col_unique_counts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df.columns:\n",
    "    print('')\n",
    "    print(c)\n",
    "    print(len(df[c].unique()))\n",
    "    dict_col_unique_counts[c] = len(df[c].unique())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_col_unique_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.FTJUDA2_.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in df.FTJUDA2_:\n",
    "#     try:\n",
    "#         float(i)\n",
    "#         print(i)\n",
    "#     except:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(df['FTJUDA2_'].astype(float, error='coerce'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    df[col] = df[col].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(df.applymap(lambda x: x == ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    df[col] = df[col].replace(\"\", \"-1.0\")\n",
    "    df[col] = df[col].replace(\"nan\", \"-1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(df.applymap(lambda x: x == ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(\"-1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot(df['FTJUDA2_'])\n",
    "ax.set(yscale=\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data_transformed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_chunk(chunk):\n",
    "    dict_temp_transformed_data = {}\n",
    "#     print(np.unique(chunk.index)[0])\n",
    "#     print(chunk.shape[0])\n",
    "    dict_temp_transformed_data['city'] = np.unique(chunk.index)[0]\n",
    "    for col in chunk.columns:\n",
    "        print(col)\n",
    "        if dict_col_unique_counts[col] < 30:\n",
    "            print(col)\n",
    "            for cat in list(np.unique(chunk[[col]])):\n",
    "#                 print(np.unique(chunk[[col]]))\n",
    "#                 print(cat)\n",
    "                \n",
    "                dict_temp_transformed_data[col + '_' + str(cat)] = sum((chunk[[col]].values == cat).squeeze()) / len(chunk)\n",
    "#                 print(col + '_' + str(cat))\n",
    "#                 print(dict_temp_transformed_data[col + '_' + str(cat)])\n",
    "        else:\n",
    "            dict_temp_transformed_data[col + '_mean'] = np.mean(chunk.loc[:, col].values)\n",
    "            print(np.mean(chunk.loc[:, col].values))\n",
    "            \n",
    "    list_data_transformed.append(dict_temp_transformed_data)  \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sth = df.groupby('city').apply(lambda chunk: transform_chunk(chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = pd.DataFrame(list_data_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Na of df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = df_transformed.fillna(df_transformed.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = df_transformed.set_index('city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot(df_transformed['FTJUDA2__mean']);\n",
    "ax.set(yscale=\"log\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = pd.plotting.scatter_matrix(df_transformed, alpha = 0.4, figsize = (14,10), diagonal = 'kde');\n",
    "corr = df_transformed.corr().as_matrix()\n",
    "for i, j in zip(*np.triu_indices_from(axes, k=1)):\n",
    "    axes[i, j].annotate(\"%.3f\" %corr[i,j], (0.8, 0.8), xycoords='axes fraction', ha='center', va='center');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize via Box-Cox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed_normed = df_transformed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_transformed_normed.columns:\n",
    "    df_transformed_normed[col] = list(stats.boxcox(df_transformed_normed[[col]])[0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed_normed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed_normed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = pd.plotting.scatter_matrix(df_transformed_normed, alpha = 0.4, figsize = (14,10), diagonal = 'kde');\n",
    "corr = df_transformed_normed.corr().as_matrix()\n",
    "for i, j in zip(*np.triu_indices_from(axes, k=1)):\n",
    "    axes[i, j].annotate(\"%.3f\" %corr[i,j], (0.8, 0.8), xycoords='axes fraction', ha='center', va='center');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed_normed_pushed = df_transformed_normed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers  = []\n",
    "\n",
    "for feature in df_transformed_normed.columns:\n",
    "    \n",
    "    Q1 = np.percentile(df_transformed_normed[feature], 25)\n",
    "    \n",
    "    Q3 = np.percentile(df_transformed_normed[feature], 75)\n",
    "    \n",
    "    step = 1.5*(Q3 - Q1)\n",
    "    \n",
    "    outliers_indices = df_transformed_normed.index[~((df_transformed_normed[feature] >= Q1 - step) \n",
    "                                                     & (df_transformed_normed[feature] <= Q3 + step))]\n",
    "    \n",
    "    if len(outliers_indices) > 0:\n",
    "\n",
    "        good_indices = list(set(df_transformed_normed_pushed.index) - set(outliers_indices))\n",
    "\n",
    "        df_transformed_normed_pushed.loc[outliers_indices, feature] = np.nanmedian(df_transformed_normed.loc[:, feature])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed_normed_pushed_zscore = pd.DataFrame(preprocessing.scale(df_transformed_normed_pushed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed_normed_pushed_zscore.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed_normed_zscore = pd.DataFrame(preprocessing.scale(df_transformed_normed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(df_transformed_normed_pushed_zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_transformed_normed = pca.transform(df_transformed_normed_zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_transformed_normed = pd.DataFrame(pca_transformed_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_transformed_normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=0, y=1, data=df_pca_transformed_normed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Do_Clustering_KMeans(components=2, data=df_pca_transformed_normed):\n",
    "    ##\n",
    "    clusterer = KMeans(n_clusters=components, random_state=0).fit(data)\n",
    "\n",
    "    preds = clusterer.predict(data)\n",
    "\n",
    "    centers = clusterer.cluster_centers_\n",
    "\n",
    "    score = silhouette_score(data, preds)\n",
    "    \n",
    "    return score, preds, centers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Best Number of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_components = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "for n_components in number_of_components:\n",
    "    score, _, _ = Do_Clustering_KMeans(components=n_components)\n",
    "    print('With {} clusters, the silhouette coefficient is {:.3f}.'.format(n_components, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_results(reduced_data, preds, centers, first_axis=0, second_axis=1, \n",
    "                    pca_samples=None, axis_min=-8, axis_max=8):\n",
    "    '''\n",
    "    Visualizes the PCA-reduced cluster data in two dimensions\n",
    "    Adds cues for cluster centers and student-selected sample data\n",
    "    '''\n",
    "\n",
    "    predictions = pd.DataFrame(preds, columns = ['Cluster'])\n",
    "    plot_data = pd.concat([predictions, reduced_data], axis = 1)\n",
    "\n",
    "    # Generate the cluster plot\n",
    "    fig, ax = plt.subplots(figsize = (9,9))\n",
    "\n",
    "    # Color map\n",
    "    cmap = cm.get_cmap('gist_rainbow')\n",
    "\n",
    "    # Color the points based on assigned cluster\n",
    "    for i, cluster in plot_data.groupby('Cluster'):   \n",
    "        cluster.plot(ax = ax, kind = 'scatter', x = first_axis, y = second_axis, \n",
    "                     color = cmap((i)*1.0/(len(centers)-1)), label = 'Cluster %i'%(i), s=30);\n",
    "\n",
    "    # Plot centers with indicators\n",
    "    for i, c in enumerate(centers):\n",
    "        ax.scatter(x = c[0], y = c[1], color = 'white', edgecolors = 'black', \\\n",
    "                   alpha = 1, linewidth = 2, marker = 'o', s=200);\n",
    "        ax.scatter(x = c[0], y = c[1], marker='$%d$'%(i), alpha = 1, s=100);\n",
    "\n",
    "    # Plot transformed sample points \n",
    "    if pca_samples is not None:\n",
    "        ax.scatter(x = pca_samples[:,0], y = pca_samples[:,1], \\\n",
    "                   s = 150, linewidth = 4, color = 'black', marker = 'x');\n",
    "\n",
    "    # Set plot title\n",
    "    ax.set_title(\"Cluster Learning on PCA Data - Centroids Marked by Number\");\n",
    "    plt.axis([axis_min, axis_max, axis_min, axis_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, preds, centers = Do_Clustering_KMeans(components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results(df_pca_transformed_normed, preds, centers, first_axis=0, second_axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results(df_pca_transformed_normed, preds, centers, first_axis=0, second_axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results(df_pca_transformed_normed, preds, centers, first_axis=0, second_axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed_normed.index[np.argmax(df_pca_transformed_normed[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed_normed.index[np.argmin(df_pca_transformed_normed[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_comp_feat = {}\n",
    "for i, comp_original in enumerate(pca.components_):\n",
    "    comp = np.abs(comp_original)\n",
    "#     print(comp)\n",
    "    out_arr = np.argsort(comp)\n",
    "    out_arr = np.flip(out_arr)\n",
    "    out_arr_first_ten = out_arr[0:20]\n",
    "    dict_temp = {}\n",
    "    dict_temp['importances'] = comp_original[out_arr_first_ten]\n",
    "    dict_temp['features'] = df_transformed_normed.columns[out_arr_first_ten]\n",
    "    dict_comp_feat[i] = dict_temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_importance(comp=None, dict_comp_feat=None, pca=None):\n",
    "\n",
    "    ratios = pca.explained_variance_ratio_ #.reshape(len(pca.components_), 1)\n",
    "\n",
    "    plt.figure(figsize=(14,8));\n",
    "    \n",
    "    components = dict_comp_feat[comp]\n",
    "    components = pd.DataFrame(components)\n",
    "\n",
    "    # Plot the feature weights as a function of the components\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_[comp]\n",
    "    g = sns.barplot(x=\"features\", y=\"importances\", data=components)\n",
    "    g.set_title(\"component {}, explained_variance_ratio is {:.2f}\".format(comp, explained_variance_ratio))\n",
    "    \n",
    "    g.set_xticklabels(g.get_xticklabels(), rotation=90)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comp in range(len(pca.components_)):\n",
    "    pca_importance(comp=comp, dict_comp_feat=dict_comp_feat, pca=pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save PCA Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Metro to PCA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_transformed_normed['city'] = df_transformed.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_transformed_normed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_transformed_normed.to_csv(\"C:/Users\\mekho\\Documents\\PycharmProjects\\Quiz_Food_LinkedIn\\data\\Food\\pca_food_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
